{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"real-abrasion-vs-incision-cnn-64x2-{}\".format(int(time.time()))\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='log/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 311ms/step - loss: 0.7696 - accuracy: 0.4819 - val_loss: 0.7067 - val_accuracy: 0.4737\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 1s 183ms/step - loss: 0.6971 - accuracy: 0.5301 - val_loss: 0.6928 - val_accuracy: 0.4211\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 1s 188ms/step - loss: 0.6894 - accuracy: 0.5723 - val_loss: 0.6967 - val_accuracy: 0.5263\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 1s 182ms/step - loss: 0.6785 - accuracy: 0.5964 - val_loss: 0.6914 - val_accuracy: 0.3158\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 1s 186ms/step - loss: 0.6580 - accuracy: 0.7169 - val_loss: 0.7322 - val_accuracy: 0.4737\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 1s 177ms/step - loss: 0.6832 - accuracy: 0.5904 - val_loss: 0.6996 - val_accuracy: 0.5263\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 1s 143ms/step - loss: 0.6158 - accuracy: 0.7048 - val_loss: 0.7082 - val_accuracy: 0.3684\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 1s 167ms/step - loss: 0.5740 - accuracy: 0.6928 - val_loss: 0.7691 - val_accuracy: 0.5789\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 1s 186ms/step - loss: 0.5813 - accuracy: 0.7169 - val_loss: 0.7411 - val_accuracy: 0.4737\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 1s 189ms/step - loss: 0.5108 - accuracy: 0.7771 - val_loss: 0.7886 - val_accuracy: 0.4737\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 1s 172ms/step - loss: 0.4430 - accuracy: 0.8133 - val_loss: 1.2567 - val_accuracy: 0.5263\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 1s 185ms/step - loss: 0.4495 - accuracy: 0.7711 - val_loss: 0.9669 - val_accuracy: 0.2105\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 1s 154ms/step - loss: 0.3789 - accuracy: 0.8554 - val_loss: 0.9435 - val_accuracy: 0.3684\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 1s 158ms/step - loss: 0.3361 - accuracy: 0.8855 - val_loss: 1.1111 - val_accuracy: 0.3158\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 1s 151ms/step - loss: 0.3244 - accuracy: 0.8434 - val_loss: 1.2288 - val_accuracy: 0.3684\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 1s 160ms/step - loss: 0.2660 - accuracy: 0.9096 - val_loss: 1.3000 - val_accuracy: 0.4211\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 1s 164ms/step - loss: 0.2303 - accuracy: 0.9096 - val_loss: 1.4648 - val_accuracy: 0.3684\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 1s 166ms/step - loss: 0.2136 - accuracy: 0.9036 - val_loss: 1.4252 - val_accuracy: 0.3684\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 1s 166ms/step - loss: 0.1824 - accuracy: 0.9518 - val_loss: 1.4982 - val_accuracy: 0.3684\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 1s 157ms/step - loss: 0.1488 - accuracy: 0.9458 - val_loss: 1.9133 - val_accuracy: 0.3684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26549b91bb0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = np.array(pickle.load(open(\"X.pickle\", \"rb\")))\n",
    "y = np.array(pickle.load(open(\"y.pickle\", \"rb\")))\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "# Input layer\n",
    "model.add(Conv2D(64, (3,3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Hidden Layer\n",
    "            \n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "model.add(Flatten())\n",
    "            \n",
    "            \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, validation_split=0.1, epochs=20, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "รอยตัด\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "import cv2\n",
    "\n",
    "CATEGORIES = [\"ถลอก\", \"รอยตัด\"]\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 64\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "prediction = model.predict([prepare('incis.jpg')])\n",
    "print(CATEGORIES[int(prediction[0][0])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tensorflowlearn\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('tensorflowlearn')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "126196daa1c7e08c8236c639998afd1ec0d96bbebe1aa23b7cfdad22ca6b0e79"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
